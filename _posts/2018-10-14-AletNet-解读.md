---
layout:     post
title:      AlexNet笔记
subtitle:   让卷积神经网络重新进入大众视野
date:       2018-10-14
author:     Ed He
catalog: true
tags:
    - Deep Learning
    - CNN
---

AlexNet是Hinton的学生Alex提出的一个卷积神经网络，最早用于ILSVRC-2010的比赛中，轰动一时。其中包括了五个卷积层和三个全连接FC层，迫于当时显卡的显存限制，在训练的时候使用了两块Geforce GTX 580 3GB显卡，其有如下特点：

1. 使用Overlapping Maxpooling代替Mean Pooling，避免其带来的模糊效果；
2. 使用ReLU作为激活函数；
3. 在非线性激活函数后使用了局部响应归一化（Local Response Normalization)，抑制响应小的神经元，提升模型泛化能力;
4. 对前两个FC层使用50%的Dropout抑制过拟合。

LRN的具体实现是：

![LRN](https://ws1.sinaimg.cn/large/006tNbRwgy1fw7zqia3tij30po05mdgk.jpg)

其中a是当前的响应值（经过卷积操作和ReLU激活函数之后），求和操作是针对当前响应值的feature map前后共n个feature map来进行的，其他参数是超参数。

比较有意思的是后面提出的VGG模型说这个LRN没什么用，而且还会增加内存使用量和计算时间。在AlexNet文章中其实LRN能给出的提升也只是1.4% for top1 error and 1.2% for top5 error。而且后续提出的模型基本也很少使用这个LRN。
